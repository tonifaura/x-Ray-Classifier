# WebApp de ClasificaciÃ³n de RadiografÃ­as con IA Interpretable
Este proyecto es una webapp que clasifica radiografÃ­as segÃºn la parte del cuerpo utilizando un modelo de deep learning. AdemÃ¡s, incorpora herramientas de explicabilidad como Grad-CAM++ y niveles de confianza para mejorar la interpretabilidad de las predicciones.

### Demo
[![Video en YouTube](https://img.youtube.com/vi/1CS3Zk7abdE/maxresdefault.jpg)](https://youtu.be/1CS3Zk7abdE?si=pC-3P6x4yg-vsDty)

---

## Ãndice
0. [Demo](#demo)
1. [IntroducciÃ³n y MotivaciÃ³n](#introducciÃ³n-y-motivaciÃ³n)
3. [Objetivos del Proyecto](#objetivos-del-proyecto)
4. [Conjunto de Datos](#conjunto-de-datos)
5. [Preprocesamiento y Limpieza](#preprocesamiento-y-limpieza)
6. [Aumento de Datos](#aumento-de-datos)
7. [Modelo Utilizado](#modelo-utilizado)
9. [Resultados](#resultados)
10. [Explicabilidad](#explicabilidad)
11. [Deployment](#deployment)
12. [Conclusiones y PrÃ³ximos Pasos](#conclusiones-y-prÃ³ximos-pasos)

---

## IntroducciÃ³n y MotivaciÃ³n

Este proyecto naciÃ³ como un reto del mÃ¡ster, en el que junto a dos compaÃ±eros, trabajamos con un dataset de +1.200 radiografÃ­as para entrenar un modelo de clasificaciÃ³n.
Posteriormente decidÃ­ retomarlo y llevarlo un paso mÃ¡s allÃ¡, mejorando el modelo, la interpretabilidad y la visualizaciÃ³n de las predicciones.

---

## Objetivos del Proyecto

1. **PrecisiÃ³n de ClasificaciÃ³n**: Asegurar una alta precisiÃ³n en la categorizaciÃ³n de imÃ¡genes.
2. **Eficiencia Computacional**: Mejorar la velocidad de procesamiento para una mayor escalabilidad.
3. **Confianza en las Predicciones**: Proporcionar un indicador de confianza para cada clasificaciÃ³n, permitiendo evaluar la fiabilidad del modelo.
4. **Interpretabilidad**: Implementar tÃ©cnicas de explicabilidad para visualizar quÃ© zonas de la imagen han influido en la predicciÃ³n.

---

## Conjunto de Datos

- **Cantidad**: 1278 imÃ¡genes de entrenamiento y 328 de prueba.
- **Formato**: ImÃ¡genes en formato DICOM.
- **Etiquetas**:

   Abdomen = 0

   Tobillo = 1

   Columna cervical = 2

   TÃ³rax = 3

   ClavÃ­culas = 4

   Codo = 5

   Pies = 6

   Dedos = 7

   Antebrazo = 8

   Mano = 9

   Cadera = 10

   Rodilla = 11

   Pierna = 12

   Columna lumbar = 13

   Otros = 14

   Pelvis = 15

   Hombro = 16

   Senos paranasales = 17

   CrÃ¡neo = 18

   Muslo = 19

   Columna torÃ¡cica = 20

   MuÃ±eca = 21

- **CaracterÃ­sticas Adicionales**: Cada imagen cuenta con un `SOPInstanceUID` Ãºnico y una columna `target` para la categorÃ­a.

---

## Preprocesamiento y Limpieza

- **TamaÃ±o de Imagen**: Redimensionado a 256x256 pÃ­xeles.
- **Formatos**: ConversiÃ³n de DICOM a PNG.
- **Escala de Color**: Escala monocromÃ¡tica (`Monochrome2`) con normalizaciÃ³n de valores entre -1 y 1.
- **Limpieza de Dataset**: EliminaciÃ³n de imÃ¡genes irrelevantes, como aquellas que no correspondÃ­an a radiografÃ­as vÃ¡lidas.

---

## Aumento de Datos

Para mejorar la variabilidad del conjunto de entrenamiento, se aplicaron las siguientes tÃ©cnicas de aumento de datos:

- **Rotaciones**: Hasta 20 grados, ademÃ¡s de rotaciones de 90 grados.
- **Traslaciones**: Horizontales y verticales.
- **Recortes (shear)**: Modificaciones en la forma de la imagen.
- **Zoom**: SimulaciÃ³n de acercamientos y alejamientos.

---

## Modelo Utilizado

Este modelo se basa en la arquitectura **DenseNet201** de Keras, preentrenada con los pesos de ImageNet. 

El modelo utiliza un enfoque de transfer learning, donde las primeras capas de DenseNet201 se mantienen congeladas para aprovechar las caracterÃ­sticas aprendidas previamente, mientras que las capas posteriores son ajustadas para la tarea especÃ­fica. Se aÃ±aden capas adicionales de procesamiento, incluyendo un GlobalAveragePooling2D seguido de una capa Dense con 1024 unidades y una capa final de clasificaciÃ³n con 22 salidas, usando softmax para la clasificaciÃ³n multiclase. El modelo es optimizado con el optimizador Adam y la funciÃ³n de pÃ©rdida sparse_categorical_crossentropy.

- **TamaÃ±o del modelo**: 14 MB
- **ParÃ¡metros**: 32 M
- **Profundidad**: 710 capas

---

## Resultados

| Conjunto       | Accuracy | Loss   |
|----------------|----------|--------|
| Entrenamiento  | 0.9777   | 0.0669 |
| ValidaciÃ³n     | 0.9727   | 0.1454 |

*_epoch 12._

---

## Explicabilidad

### Confianza en las Predicciones
Para evaluar quÃ© tan segura es cada clasificaciÃ³n, el modelo usa Softmax, una funciÃ³n que convierte las predicciones en probabilidades. La confianza es simplemente la probabilidad mÃ¡s alta entre todas las clases posibles.

- Sistema de colores en la webapp: 

ğŸŸ¢ Verde â†’ Confianza > 90% (PredicciÃ³n muy segura)

ğŸŸ  Naranja â†’ Confianza entre 70%-90% (PredicciÃ³n razonable)

ğŸ”´ Rojo â†’ Confianza < 70% (PredicciÃ³n incierta, posible error del modelo)

Este enfoque permite a los usuarios evaluar cuÃ¡ndo confiar en la predicciÃ³n y cuÃ¡ndo tomarla con cautela.


### VisualizaciÃ³n con Grad-CAM++
Para mejorar la interpretabilidad, la app incorpora Grad-CAM++ en la Ãºltima capa convolucional de la red. Esta tÃ©cnica genera mapas de calor que muestran quÃ© regiones de la imagen activaron mÃ¡s el modelo en su predicciÃ³n.

Â¿Por quÃ© es Ãºtil?

Permite verificar si el modelo se estÃ¡ fijando en la regiÃ³n correcta.
Ayuda a detectar sesgos (ej. si clasifica por bordes o texto en la imagen en lugar de la anatomÃ­a).
Refuerza la confianza del usuario al mostrar cÃ³mo el modelo tomÃ³ la decisiÃ³n.

Capa utilizada: En este modelo, la visualizaciÃ³n con Grad-CAM++ se genera a partir de la activaciÃ³n de la capa conv5_block30_concat de DenseNet201, en lugar de la Ãºltima (conv5_block32_concat). Esto permite obtener mapas de calor mÃ¡s interpretables en este caso especÃ­fico.

---

## Deployment

 CaracterÃ­sticas de la webapp:
 - Subida de imÃ¡genes para clasificaciÃ³n inmediata.
- Historial de predicciones para revisar y comparar resultados previos.
- Modo de visualizaciÃ³n flexible: permite analizar imÃ¡genes de una en una en tamaÃ±o grande o procesar mÃºltiples imÃ¡genes simultÃ¡neamente, simulando un flujo de trabajo real en entornos mÃ©dicos.
- Interfaz optimizada con cuadrÃ­culas y controles globales en la barra lateral para una navegaciÃ³n eficiente.

---

## Conclusiones y PrÃ³ximos Pasos

Este proyecto demuestra que la interpretabilidad es clave en cualquier soluciÃ³n de IA mÃ©dica, incluso en problemas sencillos como la clasificaciÃ³n de radiografÃ­as por parte del cuerpo. La incorporaciÃ³n de confianza en las predicciones y visualizaciÃ³n con Grad-CAM++ permite a los usuarios entender mejor el modelo y evaluar su fiabilidad.

AdemÃ¡s, utilizar DenseNet201 con Transfer Learning ha permitido obtener buenos resultados con un conjunto de datos limitado (1.200 imÃ¡genes), acelerando el entrenamiento y mejorando la generalizaciÃ³n.

1. **AmpliaciÃ³n del dataset**: Aumentar la cantidad y diversidad de imÃ¡genes para mejorar la robustez del modelo, o para poder usar un modelo menos pesado.
2. **Explicabilidad avanzada**: En lugar de un Ãºnico mapa de calor, generar una animaciÃ³n (GIF) con la progresiÃ³n de activaciones a travÃ©s de diferentes capas/bloques del modelo. Esto ayudarÃ­a a visualizar mejor cÃ³mo el modelo procesa la imagen.
3. **AplicaciÃ³n en DetecciÃ³n de AnomalÃ­as**: Explorar la integraciÃ³n de tÃ©cnicas de detecciÃ³n de anomalÃ­as para identificar posibles fracturas o patologÃ­as.
4. **ImplementaciÃ³n de un backend**: Mejorar la escalabilidad y permitir el uso de la API por otras aplicaciones.
5. **Mejor experiencia de usuario**
